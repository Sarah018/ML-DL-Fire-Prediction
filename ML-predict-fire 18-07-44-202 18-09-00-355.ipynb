{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import linspace\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import pingouin as pg\n",
    "from itertools import combinations\n",
    "from itertools import combinations\n",
    "import seaborn as sns\n",
    "import ppscore as pps\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.colors import ListedColormap\n",
    "import scipy.stats as ss\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy import stats\n",
    "from scipy import interpolate\n",
    "from scipy.stats.kde import gaussian_kde\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import (KNeighborsClassifier,\n",
    "                               NeighborhoodComponentsAnalysis)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rSubset(arr, r):\n",
    "    # return list of all subsets of length r\n",
    "    # to deal with duplicate subsets use\n",
    "    # set(list(combinations(arr, r)))\n",
    "    return list(combinations(arr, r))\n",
    "\n",
    "\n",
    "# Driver Function\n",
    "if __name__ == \"__main__\":\n",
    "    arr = [1, 2, 3, 4]\n",
    "    r = 2\n",
    "    # print(rSubset(arr, r))\n",
    "\n",
    "\n",
    "def createList(r1, r2):\n",
    "    # Testing if range r1 and r2\n",
    "    # are equal\n",
    "    if (r1 == r2):\n",
    "        return r1\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Create empty list\n",
    "        res = []\n",
    "\n",
    "        # loop to append successors to\n",
    "        # list until r2 is reached.\n",
    "        while (r1 < r2 + 1):\n",
    "            res.append(r1)\n",
    "            r1 += 1\n",
    "        return res\n",
    "\n",
    "\n",
    "def nans(shape, dtype=float):\n",
    "    a = np.empty(shape, dtype)\n",
    "    a.fill(np.nan)\n",
    "    return a\n",
    "\n",
    "\n",
    "def readcsv(filename):\n",
    "    with open(filename, 'r') as dest_f:\n",
    "        data_iter = csv.reader(dest_f, delimiter=',', quotechar='\"')\n",
    "        data = [data for data in data_iter]\n",
    "    data_array = np.asarray(data)\n",
    "    return data_array\n",
    "\n",
    "# Python\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_der(x):\n",
    "    return sigmoid(x) *(1-sigmoid (x))\n",
    "\n",
    "def softmax(A):\n",
    "    expA = np.exp(A)\n",
    "    return expA / expA.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_index = [\n",
    "            4,9,30,38,\n",
    "             39\n",
    "            ]\n",
    "var_Name = [\n",
    "            'LAI','LST','WA','Snow',\n",
    "            'burn_index'\n",
    "            ]\n",
    "months = ['Oct.', 'Nov.', 'Dec.', 'Jan.', 'Feb.', 'Mar.', 'Apr.', 'May', 'June', 'July', 'Aug.', 'Sept.']\n",
    "MONTHS = ['10', '11', '12', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "seasons = ['Boreal fall-winter', 'Boreal spring-summer']\n",
    "season_index = [[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10, 11]]\n",
    "continent_ID = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "continent_list = ['Africa', 'Europe', 'Siberia', 'Asia', 'Australia', 'Northern South America', 'North America',\n",
    "                  'Arctic(North America)', 'Greenland']\n",
    "\n",
    "# ****************************************** Burn + Unburn *************************************************************\n",
    "Data_Burn = np.load('/Users/yunxiazhao/Documents/AAA_burnSnow/data8_10km_monthly/data_100km_2/Burn_YearlyAverage_16years_1BF_14AF.npy')\n",
    "Data_Unbn = np.load('/Users/yunxiazhao/Documents/AAA_burnSnow/data8_10km_monthly/data_100km_2/Unbn_YearlyAverage_16years_1BF_14AF.npy')\n",
    "pc = np.shape(var_index)[0] - 1\n",
    "size_burn = np.shape(Data_Burn)\n",
    "size_unbn = np.shape(Data_Unbn)\n",
    "var_total = size_burn[2]\n",
    "\n",
    "Data_Burn_2 = np.zeros((size_burn[0],size_burn[1],size_burn[2]+1))\n",
    "Data_Unbn_2 = np.zeros((size_burn[0],size_burn[1],size_burn[2]+1))\n",
    "Data_Burn_2[:,:,0:size_burn[2]] = Data_Burn\n",
    "Data_Burn_2[:,:,size_burn[2]] = 1\n",
    "Data_Unbn_2[:,:,0:size_burn[2]] = Data_Unbn\n",
    "Data_Unbn_2[:,:,size_burn[2]] = -1\n",
    "Data_all = np.zeros((1,size_burn[1]*2,size_burn[2]+1))\n",
    "Data_all[:,0:size_burn[1],:] = Data_Burn_2[0,:,:]\n",
    "Data_all[:,size_burn[1]:size_burn[1]*2,:] = Data_Unbn_2[0,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_lat:0-25, 25-50, 50-70\n",
    "shape = np.shape(Data_all)\n",
    "data_lat_0 = np.zeros((shape[0], shape[1], shape[2]))\n",
    "data_lat_0[:] = np.nan\n",
    "index_0 = 0\n",
    "\n",
    "data_lat_25 = np.zeros((shape[0], shape[1], shape[2]))\n",
    "data_lat_25[:] = np.nan\n",
    "index_25 = 0\n",
    "\n",
    "data_lat_50 = np.zeros((shape[0], shape[1], shape[2]))\n",
    "data_lat_50[:] = np.nan\n",
    "index_50 = 0\n",
    "\n",
    "for j in range(0, shape[0]):\n",
    "    for k in range(0, shape[1]):\n",
    "        lat = Data_all[j, k, 17]\n",
    "        if lat < 25:\n",
    "            data_lat_0[j, k, :] = Data_all[j, k, :]\n",
    "        if 25 <= lat < 50:\n",
    "            data_lat_25[j, k, :] = Data_all[j, k, :]\n",
    "        if 50 <= lat < 70:\n",
    "            data_lat_50[j, k, :] = Data_all[j, k, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML & Partial Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_size = 40\n",
    "plt.rc('font', family='serif', size=font_size)\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "plt.subplots_adjust(hspace=0.3, bottom=0.2, top=0.99, right=0.95, left=0.2)\n",
    "\n",
    "\n",
    "Burn_pred = np.zeros(4)\n",
    "Unburn_pred = np.zeros(4)\n",
    "Burn_obs = np.zeros(4)\n",
    "Unburn_obs =np.zeros(4)\n",
    "\n",
    "for option3 in range(0, 4):\n",
    "    if option3 == 0:\n",
    "        Data = data_lat_0[:, :, var_index]\n",
    "        latName = '0-25°N'\n",
    "    if option3 == 1:\n",
    "        Data = data_lat_25[:, :, var_index]\n",
    "        latName = '25-50°N'\n",
    "    if option3 == 2:\n",
    "        Data = data_lat_50[:, :, var_index]\n",
    "        latName = '50-70°N'\n",
    "    if option3 == 3:\n",
    "        Data = Data_all[:, :, var_index]\n",
    "        latName = 'NH'\n",
    "\n",
    "    # Data = Data.reshape(-1, pc + 1)\n",
    "    Data = np.nanmean(Data, axis=0)\n",
    "    Data = Data[~np.isnan(Data).any(axis=1)]\n",
    "\n",
    "\n",
    "    # ************************************* Partial Correlation *******************\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(Data[:,0:pc], Data[:,pc], test_size=0.25, random_state=0)\n",
    "\n",
    "    importance = np.zeros((pc, 2))\n",
    "    X = pd.DataFrame(data=Data, columns=var_Name)\n",
    "\n",
    "\n",
    "    for i_index in range(0, pc):\n",
    "        index_list = list(range(pc))\n",
    "        index_list.remove(i_index)\n",
    "        removed_varName = [var_Name[i] for i in index_list]\n",
    "\n",
    "        pt = pg.partial_corr(data=X, x=var_Name[i_index], y=var_Name[pc], covar=removed_varName)\n",
    "        pt = pt._values\n",
    "        pt_r = pt[0, 1]\n",
    "        pt_p = pt[0, 3]\n",
    "        print(pt_p)\n",
    "        importance[i_index, 0] = pt_r\n",
    "        importance[i_index, 1] = pt_p\n",
    "\n",
    "\n",
    "    font_size = 30\n",
    "    plt.rc('font', family='serif', size=font_size)\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    plt.subplots_adjust(left=0.2)\n",
    "    # x_pos = np.arange(len(var_Name[0:pc]))\n",
    "    # ax.bar(x_pos, importance[:, 0])\n",
    "    # ax.set_xticks(x_pos)\n",
    "    # ax.set_xticklabels(var_Name[0:pc])\n",
    "    # ax.invert_yaxis()  # labels read top-to-bottom\n",
    "\n",
    "    perm_importance = importance[:, 0]\n",
    "    sorted_idx = perm_importance.argsort()\n",
    "    sorted_name = [var_Name[i] for i in sorted_idx]\n",
    "\n",
    "    x_pos = np.arange(len(sorted_name))\n",
    "    performance = perm_importance[sorted_idx]\n",
    "\n",
    "    ax.bar(x_pos, performance, width=0.3)\n",
    "    if np.nanmin(performance) * np.nanmax(performance) < 0:\n",
    "        ax.axhline(y=0, color='black', lw=2)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(sorted_name)\n",
    "\n",
    "    ax.spines['top'].set_linewidth(1)\n",
    "    ax.spines['bottom'].set_linewidth(1)\n",
    "    ax.spines['left'].set_linewidth(1)\n",
    "    ax.spines['right'].set_linewidth(1)\n",
    "\n",
    "\n",
    "    # plt.ylabel(\"r\")\n",
    "    # plt.xlabel(\"Variable\")\n",
    "    plt.title(latName)\n",
    "    # plt.xticks(rotation=45)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    output = '/Users/yunxiazhao/Documents/AAA_burnSnow/results7_10km_burn/ML/partialCor/X_all/' + latName  + '_partialR_' + \"{:.2f}\".format(\n",
    "        importance[0, 0]) + '_' + \"{:.2f}\".format(importance[1, 0])+ '_' + \"{:.2f}\".format(importance[2, 0])+ '_' + \"{:.2f}\".format(importance[3, 0]) + '_partialP_' + \"{:.2f}\".format(\n",
    "        importance[0,1]) + '_' + \"{:.2f}\".format(importance[1, 1])+ '_' + \"{:.2f}\".format(importance[2,1])+ '_' + \"{:.2f}\".format(importance[3, 1]) + '.png'\n",
    "\n",
    "    plt.savefig(output, transparent=True, dpi=100)\n",
    "\n",
    "\n",
    "    # # ************************************* ML ************************************************************************************************************************************************************************\n",
    "    y = Data[:, pc].reshape(-1, 1)\n",
    "    X = Data[:, 0:pc]\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "    # print('burn,',np.count_nonzero(y_val == 1))\n",
    "    # # print('unburn,', np.count_nonzero(y_val == -1))\n",
    "    \n",
    "    # # ******************* Decision Tree **********************************\n",
    "    \n",
    "    decision_tree = DecisionTreeClassifier(max_depth=4)\n",
    "    decision_tree = decision_tree.fit(X_tr, y_tr)\n",
    "    y_pred = decision_tree.predict(X_val).reshape(-1, 1)\n",
    "    acc = metrics.accuracy_score(y_val, y_pred)\n",
    "    print('decisionTree_acc', acc)\n",
    "    #\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "    tpr = (tp) / (tp + fn)\n",
    "    tnr = (tn) / (fp + tn)\n",
    "    fpr = 1 - tnr\n",
    "    fnr = 1 - tpr\n",
    "    ppv = (tp) / (fp + tp)\n",
    "    npv = (tn) / (fn + tn)\n",
    "    YI = tpr + tnr - 1\n",
    "    MCC = (tp * tn - fp * fn) / (np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)))\n",
    "    f1 = (2 * ppv * tpr) / (ppv + tpr)\n",
    "    \n",
    "    y_pred_proba = decision_tree.predict_proba(X_val)[::, 1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_val, y_pred_proba)\n",
    "    auc = metrics.roc_auc_score(y_val, y_pred_proba)\n",
    "    print('decisionTree_auc', auc)\n",
    "    \n",
    "    \n",
    "    filtered_var = var_Name[0:pc]\n",
    "    r = export_text(decision_tree, feature_names=filtered_var)\n",
    "    \n",
    "    output = '/Users/yunxiazhao/Documents/AAA_burnSnow/results7_10km_burn/ML/decisionTree/' \\\n",
    "             + 'lat' + latName + '_acc_' + \"{:.2f}\".format(acc) + '.txt'\n",
    "    text_file = open(output, \"w\")\n",
    "    text_file.write(r)\n",
    "    text_file.close()\n",
    "    \n",
    "    \n",
    "    font_size = 40\n",
    "    plt.rc('font', family='serif', size=font_size)\n",
    "    fig, ax = plt.subplots(figsize=(20, 15))\n",
    "    # plt.subplots_adjust(hspace=0.3, bottom=0.2, top=0.99, right=0.95, left=0.2)\n",
    "    \n",
    "    perm_importance = permutation_importance(decision_tree, X_tr, y_tr)\n",
    "    sorted_idx = perm_importance.importances_mean.argsort()\n",
    "    sorted_name = [var_Name[i] for i in sorted_idx]\n",
    "    \n",
    "    x_pos = np.arange(len(sorted_name))\n",
    "    performance = perm_importance.importances_mean[sorted_idx]\n",
    "    error = perm_importance.importances_std[sorted_idx]\n",
    "    # ax.bar(x_pos, performance, xerr=error, align='center')\n",
    "    ax.bar(x_pos, performance, yerr=error, align='center', ecolor='black', capsize=10)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(sorted_name)\n",
    "    \n",
    "    # ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    plt.ylabel(\"Importance\")\n",
    "    plt.xlabel(\"Predictor\")\n",
    "    plt.title(latName)\n",
    "    # plt.xticks(rotation=90)\n",
    "    # fig.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    output = '/Users/yunxiazhao/Documents/AAA_burnSnow/results7_10km_burn/ML/decisionTree/' \\\n",
    "             + 'lat' + latName + '_acc_' + \"{:.2f}\".format(acc) + '.png'\n",
    "    \n",
    "    plt.savefig(output, transparent=True, dpi=100)\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    #\n",
    "    font_size = 50\n",
    "    plt.rc('font', family='serif', size=font_size)\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    plt.subplots_adjust(hspace=0.3, bottom=0.2, top=0.99, right=0.95, left=0.2)\n",
    "    y_pred_proba = decision_tree.predict_proba(X_val)[::, 1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_val, y_pred_proba)\n",
    "    auc = metrics.roc_auc_score(y_val, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=\"auc=\" + \"{:.2f}\".format(auc))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    output = '/Users/yunxiazhao/Documents/AAA_burnSnow/results7_10km_burn/ML/decisionTree/' \\\n",
    "             + 'auc_lat_' + latName + '_auc_' + \"{:.2f}\".format(auc) + '.png'\n",
    "    \n",
    "    plt.savefig(output, transparent=True, dpi = 100)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    #\n",
    "    # # # *************** Logistic Regression **********************************************************************\n",
    "    #\n",
    "    logReg = LogisticRegression(random_state=0)\n",
    "    logReg.fit(X_tr, y_tr)\n",
    "    y_pred = logReg.predict(X_val)\n",
    "    acc = metrics.accuracy_score(y_val, y_pred)\n",
    "    print('logReg_acc:', acc)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "    tpr = (tp) / (tp + fn)\n",
    "    tnr = (tn) / (fp + tn)\n",
    "    fpr = 1 - tnr\n",
    "    fnr = 1 - tpr\n",
    "    ppv = (tp) / (fp + tp)\n",
    "    npv = (tn) / (fn + tn)\n",
    "    YI = tpr + tnr - 1\n",
    "    MCC = (tp * tn - fp * fn) / (np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)))\n",
    "    f1 = (2 * ppv * tpr) / (ppv + tpr)\n",
    "    \n",
    "    # y_pred_proba = logReg.predict_proba(X_val)[::, 1]\n",
    "    # fpr, tpr, _ = metrics.roc_curve(y_val, y_pred_proba)\n",
    "    # auc = metrics.roc_auc_score(y_val, y_pred_proba)\n",
    "    # print('logReg_auc', auc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    font_size = 50\n",
    "    plt.rc('font', family='serif', size=font_size)\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    # plt.subplots_adjust(hspace=0.3, bottom=0.2, top=0.99, right=0.95, left=0.2)\n",
    "    perm_importance = permutation_importance(logReg, X_val, y_val)\n",
    "    sorted_idx = perm_importance.importances_mean.argsort()\n",
    "    sorted_name = [var_Name[i] for i in sorted_idx]\n",
    "    \n",
    "    y_pos = np.arange(len(sorted_name))\n",
    "    performance = perm_importance.importances_mean[sorted_idx]\n",
    "    error = perm_importance.importances_std[sorted_idx]\n",
    "    ax.barh(y_pos, performance, xerr=error, align='center')\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(sorted_name)\n",
    "    ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Predictor\")\n",
    "    plt.xticks(rotation=90)\n",
    "    # fig.tight_layout()\n",
    "    \n",
    "    output = '/Users/yunxiazhao/Documents/AAA_burnSnow/results7_10km_burn/ML/logRegression/' \\\n",
    "             + 'lat' + latName + '_acc_' + \"{:.2f}\".format(acc) +'.png'\n",
    "    \n",
    "    plt.savefig(output, transparent=True, dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    font_size = 50\n",
    "    plt.rc('font', family='serif', size=font_size)\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    plt.subplots_adjust(hspace=0.3, bottom=0.2, top=0.99, right=0.95, left=0.2)\n",
    "    y_pred_proba = logReg.predict_proba(X_val)[::, 1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_val, y_pred_proba)\n",
    "    auc = metrics.roc_auc_score(y_val, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=\"auc=\" + \"{:.2f}\".format(auc))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    output = '/Users/yunxiazhao/Documents/AAA_burnSnow/results7_10km_burn/ML/logRegression/' \\\n",
    "             + 'auc_lat_' + latName + '_auc_' + \"{:.2f}\".format(auc) + '.png'\n",
    "    \n",
    "    plt.savefig(output, transparent=True, dpi = 100)\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    \n",
    "    # *************** Gradient boosting **********************************************************************\n",
    "    #\n",
    "    gb = GradientBoostingClassifier()\n",
    "    gb.fit(X_tr, y_tr)\n",
    "    y_pred = gb.predict(X_val)\n",
    "    acc = metrics.accuracy_score(y_val, y_pred)\n",
    "    print('gb_acc:', acc)\n",
    "    #\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "    tpr = (tp) / (tp + fn)\n",
    "    tnr = (tn) / (fp + tn)\n",
    "    fpr = 1 - tnr\n",
    "    fnr = 1 - tpr\n",
    "    ppv = (tp) / (fp + tp)\n",
    "    npv = (tn) / (fn + tn)\n",
    "    YI = tpr + tnr - 1\n",
    "    MCC = (tp * tn - fp * fn) / (np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)))\n",
    "    f1 = (2 * ppv * tpr) / (ppv + tpr)\n",
    "    \n",
    "    y_pred_proba = gb.predict_proba(X_val)[::, 1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_val, y_pred_proba)\n",
    "    auc = metrics.roc_auc_score(y_val, y_pred_proba)\n",
    "    print('gb_auc', auc)\n",
    "\n",
    "    \n",
    "    font_size = 50\n",
    "    plt.rc('font', family='serif', size=font_size)\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    # plt.subplots_adjust(hspace=0.3, bottom=0.2, top=0.99, right=0.95, left=0.2)\n",
    "    perm_importance = permutation_importance(gb, X_val, y_val)\n",
    "    sorted_idx = perm_importance.importances_mean.argsort()\n",
    "    sorted_name = [var_Name[i] for i in sorted_idx]\n",
    "    \n",
    "    y_pos = np.arange(len(sorted_name))\n",
    "    performance = perm_importance.importances_mean[sorted_idx]\n",
    "    error = perm_importance.importances_std[sorted_idx]\n",
    "    ax.barh(y_pos, performance, xerr=error, align='center')\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(sorted_name)\n",
    "    ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Predictor\")\n",
    "    plt.xticks(rotation=90)\n",
    "    # fig.tight_layout()\n",
    "    \n",
    "    output = '/Users/yunxiazhao/Documents/AAA_burnSnow/results7_10km_burn/ML/gradientBoosting/' \\\n",
    "             + 'lat' + latName + '_acc_' + \"{:.2f}\".format(acc) \\\n",
    "                     + 'tpr_' + \"{:.2f}\".format(tpr) + 'tnr_' + \"{:.2f}\".format(\n",
    "                tnr) + 'fpr_' + \"{:.2f}\".format(fpr) \\\n",
    "                     + 'fnr_' + \"{:.2f}\".format(fnr) + 'ppv_' + \"{:.2f}\".format(\n",
    "                ppv) + 'npv_' + \"{:.2f}\".format(npv) \\\n",
    "                     + 'YI_' + \"{:.2f}\".format(YI) + 'MCC_' + \"{:.2f}\".format(\n",
    "                MCC) + 'f1_' + \"{:.2f}\".format(f1) + '.png'\n",
    "    \n",
    "    plt.savefig(output, transparent=True, dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     ******************* Random Forest **********************************\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_tr, y_tr)\n",
    "    y_pred = rf.predict(X_val)\n",
    "    acc = metrics.accuracy_score(y_val, y_pred)\n",
    "    print('RandomForest:', acc)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "    tpr = (tp) / (tp + fn)\n",
    "    tnr = (tn) / (fp + tn)\n",
    "    fpr = 1 - tnr\n",
    "    fnr = 1 - tpr\n",
    "    ppv = (tp) / (fp + tp)\n",
    "    npv = (tn) / (fn + tn)\n",
    "    YI = tpr + tnr - 1\n",
    "    MCC = (tp * tn - fp * fn) / (np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)))\n",
    "    f1 = (2 * ppv * tpr) / (ppv + tpr)\n",
    "    y_pred_proba = rf.predict_proba(X_val)[::, 1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_val, y_pred_proba)\n",
    "    auc = metrics.roc_auc_score(y_val, y_pred_proba)\n",
    "    print('rf_auc', auc)\n",
    "\n",
    "    font_size = 30\n",
    "    plt.rc('font', family='serif', size=font_size)\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    plt.subplots_adjust(left=0.2)\n",
    "\n",
    "\n",
    "\n",
    "    perm_importance = permutation_importance(rf, X_val, y_val)\n",
    "\n",
    "    sorted_idx = perm_importance.importances_mean.argsort()\n",
    "    sorted_name = [var_Name[i] for i in sorted_idx]\n",
    "\n",
    "    x_pos = np.arange(len(sorted_name))\n",
    "    performance = perm_importance.importances_mean[sorted_idx]\n",
    "    error = perm_importance.importances_std[sorted_idx]\n",
    "    # ax.bar(x_pos, performance, xerr=error, align='center')\n",
    "    ax.bar(x_pos, performance, yerr=error, align='center', ecolor='black', capsize=10,width=0.3)\n",
    "    if np.nanmin(performance) * np.nanmax(performance) < 0:\n",
    "        ax.axhline(y=0, color='black', lw=2)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(sorted_name)\n",
    "\n",
    "    # ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    # plt.ylabel(\"Importance\")\n",
    "    # plt.xlabel(\"Predictor\")\n",
    "    plt.title(latName)\n",
    "    # plt.xticks(rotation=90)\n",
    "    # fig.tight_layout()\n",
    "    ax.spines['top'].set_linewidth(1)\n",
    "    ax.spines['bottom'].set_linewidth(1)\n",
    "    ax.spines['left'].set_linewidth(1)\n",
    "    ax.spines['right'].set_linewidth(1)\n",
    "    output = '/Users/yunxiazhao/Documents/AAA_burnSnow/results7_10km_burn/ML/randomForest/' \\\n",
    "             + 'lat' + latName + '_acc_' + \"{:.2f}\".format(acc) + '.png'\n",
    "\n",
    "    plt.savefig(output, transparent=True, dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    font_size = 50\n",
    "    plt.rc('font', family='serif', size=font_size)\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    plt.subplots_adjust(hspace=0.3, bottom=0.2, top=0.99, right=0.95, left=0.2)\n",
    "    y_pred_proba = rf.predict_proba(X_val)[::, 1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_val, y_pred_proba)\n",
    "    auc = metrics.roc_auc_score(y_val, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=\"auc=\" + \"{:.2f}\".format(auc))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    ax.spines['top'].set_linewidth(2)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    ax.spines['right'].set_linewidth(2)\n",
    "    output = '/Users/yunxiazhao/Documents/AAA_burnSnow/results7_10km_burn/ML/randomForest/' \\\n",
    "             + 'auc_lat_' + latName + '_auc_' + \"{:.2f}\".format(auc) + '.png'\n",
    "    \n",
    "    plt.savefig(output, transparent=True, dpi = 100)\n",
    "    plt.close()\n",
    "\n",
    "#     ********************************** Ridge Classfier ************************************************\n",
    "\n",
    "\n",
    "    from sklearn.datasets import load_breast_cancer\n",
    "    from sklearn.linear_model import RidgeClassifier\n",
    "    clf = RidgeClassifier().fit(X, y)\n",
    "    coef = clf.coef_\n",
    "    font_size = 40\n",
    "    plt.rc('font', family='serif', size=font_size)\n",
    "    fig, ax = plt.subplots(figsize=(20, 15))\n",
    "    # plt.subplots_adjust(hspace=0.3, bottom=0.2, top=0.99, right=0.95, left=0.2)\n",
    "    perm_importance = RandomForestClassifier().fit(X, y)\n",
    "    sorted_idx = perm_importance.coef_.argsort()[0]\n",
    "    sorted_name = [var_Name[i] for i in sorted_idx]\n",
    "    \n",
    "    x_pos = np.arange(len(sorted_name))\n",
    "    performance = perm_importance.coef_[0][sorted_idx]\n",
    "    error = 0\n",
    "    ax.bar(x_pos, performance, yerr=error, align='center', ecolor='black', capsize=10)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(sorted_name)\n",
    "    \n",
    "    # ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    plt.ylabel(\"Ridge coefficient\")\n",
    "    plt.xlabel(\"Predictor\")\n",
    "    plt.title(latName)\n",
    "    # plt.xticks(rotation=90)\n",
    "    # fig.tight_layout()\n",
    "    \n",
    "    output = '/Users/yunxiazhao/Documents/AAA_burnSnow/results7_10km_burn/ML/ridgeClassfier/' \\\n",
    "             + 'lat' + latName +'_RidgeCoef' + '.png'\n",
    "    \n",
    "    plt.savefig(output, transparent=True, dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "#             ******************* Plot counts **************************\n",
    "            Burn_pred[option3] = tp+fn\n",
    "            Unburn_pred[option3] = tn+fp\n",
    "            # Burn_pred[option3] = np.count_nonzero(y_pred==1)\n",
    "            # Unburn_pred[option3] =np.count_nonzero(y_pred==0)\n",
    "            Burn_obs[option3] = np.count_nonzero(y_val == 1)\n",
    "            Unburn_obs[option3] = np.count_nonzero(y_val == 0)\n",
    "\n",
    "df = pd.DataFrame(dict(Burn_pred=Burn_pred,\n",
    "                       Unburn_pred=Unburn_pred,\n",
    "                       Burn_obs=Burn_obs,\n",
    "                       Unburn_obs=Unburn_obs),\n",
    "                  ['0°-25°N', '25°-50°N', '50°-70°N', '0°-70°N'])\n",
    "\n",
    "\n",
    "ax = df[['Burn_pred', 'Unburn_pred']].plot.bar(stacked=True, position=1, width=.2, color=['red', 'green'], rot=0)\n",
    "df[['Burn_obs', 'Unburn_obs']].plot.bar(stacked=True, ax=ax, position=0, width=.2, color=['red', 'green'], rot=0)\n",
    "# ax.legend(['Burned', 'Unburned'], frameon=False)\n",
    "# ax.legend(['', ''], frameon=False)\n",
    "plt.text(0.25, 0.9, 'Predicted (left)', ha='center',\n",
    "         va='center',\n",
    "         transform=ax.transAxes, color='k')\n",
    "plt.text(0.25, 0.8, 'Observed (right)', ha='center',\n",
    "         va='center',\n",
    "         transform=ax.transAxes, color='k')\n",
    "ax.set_xlabel(\"Region\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "ax.get_legend().remove()\n",
    "plt.subplots_adjust(bottom=0.15, top=0.99, right=0.95, left=0.2)\n",
    "output = '/Users/sarah/Documents/AAA_burnSnow/results5_10km_burn/ML/randomForest/' \\\n",
    "         + 'counts' + '.png'\n",
    "plt.savefig(output, transparent=True, dpi=200)\n",
    "# plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "            # ******************* Plot AUC **************************\n",
    "    y_pred_proba = decision_tree.predict_proba(X_val)[::, 1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_val, y_pred_proba)\n",
    "    auc = metrics.roc_auc_score(y_val, y_pred_proba)\n",
    "    print(auc)\n",
    "    plt.plot(fpr, tpr, label = latName)\n",
    "\n",
    "    if option3==0:\n",
    "        auc_0 = auc\n",
    "    if option3==1:\n",
    "        auc_1 = auc\n",
    "    if option3==2:\n",
    "        auc_2 = auc\n",
    "    if option3==3:\n",
    "        auc_3 = auc\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\", frameon=False)\n",
    "\n",
    "output = '/Users/sarah/Documents/AAA_burnSnow/results5_10km_burn/ML/decisionTree/' \\\n",
    "         'auc_0_25_'+  \"{:.2f}\".format(auc_0)  + '_auc_25_50_'+  \"{:.2f}\".format(auc_1)  + '_auc_50_70_'+  \"{:.2f}\".format(auc_2)  + '_auc_0_70_'+  \"{:.2f}\".format(auc_3)  + '.png'\n",
    "\n",
    "plt.savefig(output, transparent=True, dpi=100)\n",
    "plt.close()\n",
    "\n",
    "#             ******************* Plot PRC **************************\n",
    "    prec, recall, _ = precision_recall_curve(y_val, y_pred)\n",
    "    plt.plot(prec, recall, label=latName)\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower left\", frameon=False)\n",
    "output = '/Users/sarah/Documents/AAA_burnSnow/results5_10km_burn/ML/randomForest/' \\\n",
    "         + 'prc'  + '.png'\n",
    "\n",
    "plt.savefig(output, transparent=True, dpi=100)\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
