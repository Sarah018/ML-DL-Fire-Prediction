{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import glob\n",
    "import csv\n",
    "\n",
    "def readcsv(filename):\n",
    "    with open(filename, 'r') as dest_f:\n",
    "        data_iter = csv.reader(dest_f, delimiter=',', quotechar='\"')\n",
    "        data = [data for data in data_iter]\n",
    "    data_array = np.asarray(data)\n",
    "    return data_array\n",
    "\n",
    "\n",
    "def removeRows(var, data, a):\n",
    "    del_len = int(np.shape(var)[0])\n",
    "    del_rows = []\n",
    "    for i in range(0, a):\n",
    "        for k in range(0, del_len):\n",
    "            if(data[i, 0]==var[k]):\n",
    "                del_rows.append(i)\n",
    "    data = np.delete(data, del_rows, axis=0)\n",
    "                      \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvsTOndarray(dataTag, fld, outputFLD,extra_col):\n",
    "    for year in range(0, 3):\n",
    "        file_base_burn = fld[228*(year)]\n",
    "        data_base_burn = readcsv(file_base_burn)\n",
    "        shape_base_burn = np.shape(data_base_burn)\n",
    "        a = shape_base_burn[0] - 1\n",
    "        b = shape_base_burn[1] \n",
    "        data_all = np.zeros((waterYearLen, 12, a, b+extra_col))\n",
    "        \n",
    "        \n",
    "        fld_unbn = sorted(glob.glob(path +'Unbn'+ '_0909_100km/*.csv'))\n",
    "        file_base_unbn = fld_unbn[228*(year)]\n",
    "        data_base_unbn = readcsv(file_base_unbn)\n",
    "        \n",
    "        ID_burn = data_base_burn[1:a+1, 0]\n",
    "        ID_unbn = data_base_unbn[1:a+1, 0]\n",
    "        \n",
    "        ID_dif_burn = list(set(ID_burn) - set(ID_unbn))\n",
    "        ID_dif_unbn = list(set(ID_unbn) - set(ID_burn))\n",
    "        ID_dif=np.append(ID_dif_burn, ID_dif_unbn)\n",
    "       \n",
    "        \n",
    "        if dataTag == 'Burn':\n",
    "            data_all = np.zeros((19, 12, a-np.shape(ID_dif_burn)[0], b+extra_col))\n",
    "            var = np.array(ID_dif_burn).astype(float)\n",
    "        if dataTag == 'Unbn':\n",
    "            data_all = np.zeros((19, 12, a-np.shape(ID_dif_unbn)[0], b+extra_col)) \n",
    "            var = np.array(ID_dif_unbn).astype(float)\n",
    "   \n",
    "        for i in range(months_total*(year), months_total*(year+1)):\n",
    "            fireYear = waterYearStart+year\n",
    "            file = fld[i]\n",
    "#             print(file)\n",
    "            data = readcsv(file)\n",
    "            data = data[1:a+1,0:b]\n",
    "            data[data == ''] = np.nan\n",
    "            data = data.astype(float)\n",
    "            data = sorted(data, key=lambda x: x[0])\n",
    "            data = np.array(data)  \n",
    "            \n",
    "            data = removeRows(var, data, a)\n",
    "            mask_length = a- np.shape(var)[0]\n",
    "          \n",
    "            \n",
    "            waterYear = np.floor((i-228*(year))/12)\n",
    "            waterYear = int(waterYear)\n",
    "            month = int(i%12)\n",
    "\n",
    "            data_all[waterYear, month, :, 0:b] = data\n",
    "            data_all[waterYear, month, :, 11] = 10*data_all[waterYear, month, :, 11]\n",
    "            data_all[waterYear, month, :, 21] = 10*data_all[waterYear, month, :, 21]\n",
    "            data_all[waterYear, month, :, 12] = 100*data_all[waterYear, month, :, 12]\n",
    "            \n",
    "            data_all[waterYear, month, :, b] = data[:,20]-data[:,19]\n",
    "            data_all[waterYear, month, :, b+1] = data[:,8] - data[:,7] \n",
    "            data_all[waterYear, month, :, b+2] = data[:,11] - data[:,7]\n",
    "            data_all[waterYear, month, :, b+3] = data[:,11] - data[:,8]\n",
    "            \n",
    "            data_all[waterYear, month, :, b+4] = data[:,9]*1.1*10\n",
    "            mask = np.zeros((mask_length,1))\n",
    "            index_1 = np.where(data[:,9]<0)\n",
    "            mask[index_1,0] = 0\n",
    "            index_2 = np.logical_and(data[:,10]<1,data[:,9]>0)\n",
    "            \n",
    "            mask[index_2,0] = data[index_2,10]*0.0133+0.0667\n",
    "            index_3 = np.where(data[:,9]>=1)\n",
    "            mask[index_3,0] = 0.08\n",
    "            data_all[waterYear, month, :, b+4] =data_all[waterYear, month, :, b+4]*mask[:,0]\n",
    "            mask_rad = np.zeros((a,1))\n",
    "            index_rad = np.where(data[:,17]>0)\n",
    "            mask[index_rad,0] = 1\n",
    "            data_all[waterYear, month, :, b+4] = data_all[waterYear, month, :, b+4] + 0.026*data[:,17]*mask[:,0]\n",
    "            \n",
    "            \n",
    "            data_all[waterYear, month, :, b+5] = data[:,10]*1.1*10\n",
    "            mask = np.zeros((mask_length,1))\n",
    "            index_1 = np.where(data[:,10]<0)\n",
    "            mask[index_1,0] = 0\n",
    "            index_2 = np.logical_and(data[:,10]<1,data[:,10]>0)\n",
    "            mask[index_2,0] = data[index_2,10]*0.0133+0.0667\n",
    "            index_3 = np.where(data[:,10]>=1)\n",
    "            mask[index_3,0] = 0.08\n",
    "            data_all[waterYear, month, :, b+5] =data_all[waterYear, month, :, b+5]*mask[:,0]\n",
    "            mask_rad = np.zeros((a,1))\n",
    "            index_rad = np.where(data[:,16]>0)\n",
    "            mask[index_rad,0] = 1\n",
    "            data_all[waterYear, month, :, b+5] = data_all[waterYear, month, :, b+5] + 0.026*data[:,16]*mask[:,0]\n",
    "            \n",
    "            \n",
    "            mask_temp = np.zeros((mask_length,1))\n",
    "            index_temp = np.where(data[:,22]>0)\n",
    "            mask_temp[index_temp,0] = 1\n",
    "            mask_rad = np.zeros((mask_length,1))\n",
    "            index_rad = np.where(data[:,23]>0)\n",
    "            mask_rad[index_rad,0] = 1\n",
    "            data_all[waterYear, month, :, b+6] = data[:,22]*mask_temp[:,0] + data[:,23]*mask_rad[:,0]\n",
    "            mask_temp = np.zeros((mask_length,1))\n",
    "            index_temp = np.where(data[:,25]>0)\n",
    "            mask_temp[index_temp,0] = 1\n",
    "            mask_rad = np.zeros((mask_length,1))\n",
    "            index_rad = np.where(data[:,26]>0)\n",
    "            mask_rad[index_rad,0] = 1\n",
    "            data_all[waterYear, month, :, b+7] = data[:,25]*mask_temp[:,0] + data[:,26]*mask_rad[:,0]\n",
    "            mask_temp = np.zeros((mask_length,1))\n",
    "            index_temp = np.where(data[:,22]>0)\n",
    "            mask_temp[index_temp,0] = 1\n",
    "            mask_rad = np.zeros((mask_length,1))\n",
    "            index_rad = np.where(data[:,29]>0)\n",
    "            mask_rad[index_rad,0] = 1\n",
    "            data_all[waterYear, month, :, b+8] = data[:,22]*mask_temp[:,0] + data[:,29]*mask_rad[:,0]\n",
    "            mask_temp = np.zeros((mask_length,1))\n",
    "            index_temp = np.where(data[:,25]>0)\n",
    "            mask_temp[index_temp,0] = 1\n",
    "            mask_rad = np.zeros((mask_length,1))\n",
    "            index_rad = np.where(data[:,27]>0)\n",
    "            mask_rad[index_rad,0] = 1\n",
    "            data_all[waterYear, month, :, b+9] = data[:,25]*mask_temp[:,0] + data[:,27]*mask_rad[:,0]\n",
    "\n",
    "            data_all[waterYear, month, :, b+10] = data[:,21] \n",
    "        \n",
    "        for j in range(0, waterYearLen): \n",
    "            for k in range(0, 1):\n",
    "                for l in range(0, mask_length):\n",
    "                    for index in [-20,4, 5,6,7,8,9]:\n",
    "                        if data_all[j,k,l,b+index]>data_all[j,k,l,b+10]:\n",
    "                            data_all[j,k,l,b+index] = data_all[j,k,l,b+10]\n",
    "                            data_all[j,k,l,b+10] = 0\n",
    "                        else:\n",
    "                            data_all[j,k,l,b+10] -= data_all[j,k,l,b+index]\n",
    "                        \n",
    "        \n",
    "        for j in range(0, waterYearLen): \n",
    "            for k in range(1, 12):\n",
    "                for l in range(0, mask_length):\n",
    "                    for index in [-20,4, 5,6,7,8,9]:\n",
    "                        data_all[j,k,l,b+10] += data_all[j,k-1,l,b+10]\n",
    "                        \n",
    "                        if data_all[j,k,l,b+index]>data_all[j,k,l,b+10]:\n",
    "                            data_all[j,k,l,b+index] = data_all[j,k,l,b+10]\n",
    "                            data_all[j,k,l,b+10] = 0\n",
    "                        else:\n",
    "                            data_all[j,k,l,b+10] -= data_all[j,k,l,b+index]\n",
    "                        \n",
    "                              \n",
    "                    \n",
    "        output = outputFLD + str(year+2003)\n",
    "        np.save(output, data_all)\n",
    "\n",
    "# Merge Data\n",
    "extra_col = 11\n",
    "waterYearLen = 19\n",
    "months_total = 228\n",
    "waterYearStart = 2002\n",
    "path = '/Users/yunxiazhao/Documents/AAA_burnSnow/data8_10km_monthly/data_100km_3/'\n",
    "\n",
    "dataTag = 'Burn'\n",
    "fld = sorted(glob.glob(path +dataTag+ '_0909_100km/*.csv'))\n",
    "\n",
    "outputFLD = path + dataTag + '_fireYear_'\n",
    "cvsTOndarray(dataTag, fld, outputFLD,extra_col)\n",
    "\n",
    "dataTag = 'Unbn'\n",
    "fld = sorted(glob.glob(path +dataTag+ '_0909_100km/*.csv'))\n",
    "\n",
    "outputFLD = path +dataTag+ '_fireYear_'\n",
    "cvsTOndarray(dataTag, fld, outputFLD,extra_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 12, 4990, 43)\n",
      "(19, 12, 4664, 43)\n",
      "(19, 12, 4805, 43)\n"
     ]
    }
   ],
   "source": [
    "len_YearAF = 17\n",
    "waterYearLen = 19\n",
    "months_total = 228\n",
    "path = '/Users/yunxiazhao/Documents/AAA_burnSnow/data8_10km_monthly/data_100km_3/'\n",
    "\n",
    "Data_Burn_2004 = np.load(path+'Burn_fireYear_2003.npy')\n",
    "Data_Burn_2005 = np.load(path+'Burn_fireYear_2004.npy')\n",
    "Data_Burn_2006 = np.load(path+'Burn_fireYear_2005.npy')\n",
    "\n",
    "Data_Unbn_2004 = np.load(path+'Unbn_fireYear_2003.npy')\n",
    "Data_Unbn_2005 = np.load(path+'Unbn_fireYear_2004.npy')\n",
    "Data_Unbn_2006 = np.load(path+'Unbn_fireYear_2005.npy')\n",
    "\n",
    "Data_Dif_2004 = Data_Burn_2004 - Data_Unbn_2004\n",
    "Data_Dif_2005 = Data_Burn_2005 - Data_Unbn_2005\n",
    "Data_Dif_2006 = Data_Burn_2006 - Data_Unbn_2006\n",
    "\n",
    "Data_Dif_2004[:,:,:,0] = Data_Burn_2004[:,:,:,0]\n",
    "Data_Dif_2004[:,:,:,1] = Data_Burn_2004[:,:,:,1]\n",
    "Data_Dif_2004[:,:,:,2] = Data_Burn_2004[:,:,:,2]\n",
    "Data_Dif_2004[:,:,:,30] = Data_Burn_2004[:,:,:,30]\n",
    "Data_Dif_2004[:,:,:,31] = Data_Burn_2004[:,:,:,31]\n",
    "\n",
    "Data_Dif_2005[:,:,:,0] = Data_Burn_2005[:,:,:,0]\n",
    "Data_Dif_2005[:,:,:,1] = Data_Burn_2005[:,:,:,1]\n",
    "Data_Dif_2005[:,:,:,2] = Data_Burn_2005[:,:,:,2]\n",
    "Data_Dif_2005[:,:,:,30] = Data_Burn_2005[:,:,:,30]\n",
    "Data_Dif_2005[:,:,:,31] = Data_Burn_2005[:,:,:,31]\n",
    "\n",
    "Data_Dif_2006[:,:,:,0] = Data_Burn_2006[:,:,:,0]\n",
    "Data_Dif_2006[:,:,:,1] = Data_Burn_2006[:,:,:,1]\n",
    "Data_Dif_2006[:,:,:,2] = Data_Burn_2006[:,:,:,2]\n",
    "Data_Dif_2006[:,:,:,30] = Data_Burn_2006[:,:,:,30]\n",
    "Data_Dif_2006[:,:,:,31] = Data_Burn_2006[:,:,:,31]\n",
    "\n",
    "\n",
    "print(np.shape(Data_Dif_2004))\n",
    "print(np.shape(Data_Dif_2005))\n",
    "print(np.shape(Data_Dif_2006))\n",
    "\n",
    "output = path + 'Dif_fireYear_2003' \n",
    "np.save(output, Data_Dif_2004)\n",
    "\n",
    "output = path+ 'Dif_fireYear_2004' \n",
    "np.save(output, Data_Dif_2005)\n",
    "\n",
    "output = path + 'Dif_fireYear_2005' \n",
    "np.save(output, Data_Dif_2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-fd9de6bdde38>:28: RuntimeWarning: Mean of empty slice\n",
      "  Data_year[i,0:size_2004[2],:] = np.nanmean(Data_Dif_2004[i, :,:,:], axis=0)\n",
      "<ipython-input-17-fd9de6bdde38>:29: RuntimeWarning: Mean of empty slice\n",
      "  Data_year[i,size_2004[2]:size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+1, :,:,:], axis=0)\n",
      "<ipython-input-17-fd9de6bdde38>:30: RuntimeWarning: Mean of empty slice\n",
      "  Data_year[i,size_2004[2]+size_2005[2]:size_2004[2]+size_2005[2]+size_2006[2],:] = np.nanmean(Data_Dif_2006[i+2, :,:,:], axis=0)\n",
      "<ipython-input-17-fd9de6bdde38>:33: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_winter[i,0:size_2004[2],:] = np.nanmean(Data_Dif_2004[i, 0:6,:,:], axis=0)\n",
      "<ipython-input-17-fd9de6bdde38>:34: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_winter[i,size_2004[2]:size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+1, 0:6,:,:], axis=0)\n",
      "<ipython-input-17-fd9de6bdde38>:35: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_winter[i,size_2004[2]+size_2005[2]:size_2004[2]+size_2005[2]+size_2006[2],:] = np.nanmean(Data_Dif_2006[i+2,0:6,:,:], axis=0)\n",
      "<ipython-input-17-fd9de6bdde38>:37: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_summer[i,0:size_2004[2],:] = np.nanmean(Data_Dif_2004[i, 6:12,:,:], axis=0)\n",
      "<ipython-input-17-fd9de6bdde38>:38: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_summer[i,size_2004[2]:size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+1, 6:12,:,:], axis=0)\n",
      "<ipython-input-17-fd9de6bdde38>:39: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_summer[i,size_2004[2]+size_2005[2]:size_2004[2]+size_2005[2]+size_2006[2],:] = np.nanmean(Data_Dif_2006[i+2,6:12,:,:], axis=0)\n"
     ]
    }
   ],
   "source": [
    "len_YearAF = 17\n",
    "waterYearLen = 19\n",
    "months_total = 228\n",
    "path = '/Users/yunxiazhao/Documents/AAA_burnSnow/data8_10km_monthly/data_100km_3/'\n",
    "\n",
    "Data_Dif_2004 = np.load(path + 'Dif_fireYear_2003.npy' )\n",
    "Data_Dif_2005 = np.load(path+ 'Dif_fireYear_2004.npy' )\n",
    "Data_Dif_2006 = np.load(path + 'Dif_fireYear_2005.npy' )\n",
    "size_2004 = np.shape(Data_Dif_2004)\n",
    "size_2005 = np.shape(Data_Dif_2005)\n",
    "size_2006 = np.shape(Data_Dif_2006)\n",
    "\n",
    "\n",
    "len_points = size_2004[2]+size_2005[2]+size_2006[2]\n",
    "len_var = size_2004[3]\n",
    "Data_year = np.zeros((len_YearAF,len_points,len_var))\n",
    "Data_year_winter = np.zeros((len_YearAF,len_points,len_var))\n",
    "Data_year_summer = np.zeros((len_YearAF,len_points,len_var))\n",
    "Data_year[:]=np.nan\n",
    "Data_year_winter[:]=np.nan\n",
    "Data_year_summer[:]=np.nan\n",
    "for i in range(0, len_YearAF):\n",
    "    Data_year[i,0:size_2004[2],:] = np.nanmean(Data_Dif_2004[i, :,:,:], axis=0)\n",
    "    Data_year[i,size_2004[2]:size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+1, :,:,:], axis=0)\n",
    "    Data_year[i,size_2004[2]+size_2005[2]:size_2004[2]+size_2005[2]+size_2006[2],:] = np.nanmean(Data_Dif_2006[i+2, :,:,:], axis=0)\n",
    "    \n",
    "    \n",
    "    Data_year_winter[i,0:size_2004[2],:] = np.nanmean(Data_Dif_2004[i, 0:6,:,:], axis=0)\n",
    "    Data_year_winter[i,size_2004[2]:size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+1, 0:6,:,:], axis=0)\n",
    "    Data_year_winter[i,size_2004[2]+size_2005[2]:size_2004[2]+size_2005[2]+size_2006[2],:] = np.nanmean(Data_Dif_2006[i+2,0:6,:,:], axis=0)\n",
    "    \n",
    "    Data_year_summer[i,0:size_2004[2],:] = np.nanmean(Data_Dif_2004[i, 6:12,:,:], axis=0)\n",
    "    Data_year_summer[i,size_2004[2]:size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+1, 6:12,:,:], axis=0)\n",
    "    Data_year_summer[i,size_2004[2]+size_2005[2]:size_2004[2]+size_2005[2]+size_2006[2],:] = np.nanmean(Data_Dif_2006[i+2,6:12,:,:], axis=0)\n",
    "    \n",
    "    \n",
    "output_year = path  + 'Dif_YearlyAverage_17years_1BF_15AF'\n",
    "np.save(output_year, Data_year)    \n",
    "    \n",
    "output_winter = path + 'Dif_WinterAverage_17years_1BF_15AF'\n",
    "np.save(output_winter, Data_year_winter) \n",
    "    \n",
    "output_summer = path + 'Dif_SummerAverage_17years_1BF_15AF'\n",
    "np.save(output_summer, Data_year_summer) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-079132596416>:31: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_winter[i,0:size_2004[2],:] = np.nanmean(Data_Dif_2004[i, 0:3,:,:], axis=0)\n",
      "<ipython-input-15-079132596416>:32: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_winter[i,size_2004[2]:size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+1, 0:3,:,:], axis=0)\n",
      "<ipython-input-15-079132596416>:33: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_winter[i,size_2004[2]+size_2005[2]:size_2004[2]+size_2005[2]+size_2006[2],:] = np.nanmean(Data_Dif_2006[i+2,0:3,:,:], axis=0)\n",
      "<ipython-input-15-079132596416>:35: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_spring[i,0:size_2004[2],:] = np.nanmean(Data_Dif_2004[i, 3:6,:,:], axis=0)\n",
      "<ipython-input-15-079132596416>:36: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_spring[i,size_2004[2]:size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+1, 3:6,:,:], axis=0)\n",
      "<ipython-input-15-079132596416>:37: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_spring[i,size_2004[2]+size_2005[2]:size_2004[2]+size_2005[2]+size_2006[2],:] = np.nanmean(Data_Dif_2006[i+2,3:6,:,:], axis=0)\n",
      "<ipython-input-15-079132596416>:39: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_summer[i,0:size_2004[2],:] = np.nanmean(Data_Dif_2004[i, 6:9,:,:], axis=0)\n",
      "<ipython-input-15-079132596416>:40: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_summer[i,size_2004[2]:size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+1, 6:9,:,:], axis=0)\n",
      "<ipython-input-15-079132596416>:41: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_summer[i,size_2004[2]+size_2005[2]:size_2004[2]+size_2005[2]+size_2006[2],:] = np.nanmean(Data_Dif_2006[i+2,6:9,:,:], axis=0)\n",
      "<ipython-input-15-079132596416>:43: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_fall[i,0:size_2004[2],:] = np.nanmean(Data_Dif_2004[i, 9:12,:,:], axis=0)\n",
      "<ipython-input-15-079132596416>:44: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_fall[i,size_2004[2]:size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+1, 9:12,:,:], axis=0)\n",
      "<ipython-input-15-079132596416>:45: RuntimeWarning: Mean of empty slice\n",
      "  Data_year_fall[i,size_2004[2]+size_2005[2]:size_2004[2]+size_2005[2]+size_2006[2],:] = np.nanmean(Data_Dif_2006[i+2,9:12,:,:], axis=0)\n"
     ]
    }
   ],
   "source": [
    "len_YearAF = 17\n",
    "waterYearLen = 19\n",
    "months_total = 228\n",
    "path = '/Users/yunxiazhao/Documents/AAA_burnSnow/data8_10km_monthly/data_100km_3/'\n",
    " \n",
    "Data_Dif_2004 = np.load(path + 'Dif_fireYear_2003.npy' )\n",
    "Data_Dif_2005 = np.load(path+ 'Dif_fireYear_2004.npy' )\n",
    "Data_Dif_2006 = np.load(path + 'Dif_fireYear_2005.npy' )\n",
    "size_2004 = np.shape(Data_Dif_2004)\n",
    "size_2005 = np.shape(Data_Dif_2005)\n",
    "size_2006 = np.shape(Data_Dif_2006)\n",
    "# len_YearAF = 15\n",
    "len_points = size_2004[2]+size_2005[2]+size_2006[2]\n",
    "len_var = size_2004[3]\n",
    "Data_year = np.zeros((len_YearAF,len_points,len_var))\n",
    "Data_year_winter = np.zeros((len_YearAF,len_points,len_var))\n",
    "Data_year_spring= np.zeros((len_YearAF,len_points,len_var))\n",
    "Data_year_summer = np.zeros((len_YearAF,len_points,len_var))\n",
    "Data_year_fall = np.zeros((len_YearAF,len_points,len_var))\n",
    "Data_year[:]=np.nan\n",
    "Data_year_winter[:]=np.nan\n",
    "Data_year_summer[:]=np.nan\n",
    "for i in range(0, len_YearAF):\n",
    "\n",
    "    \n",
    "    Data_year_winter[i,0:size_2004[2],:] = np.nanmean(Data_Dif_2004[i, 0:3,:,:], axis=0)\n",
    "    Data_year_winter[i,size_2004[2]:size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+1, 0:3,:,:], axis=0)\n",
    "    Data_year_winter[i,size_2004[2]+size_2005[2]:size_2004[2]+size_2005[2]+size_2006[2],:] = np.nanmean(Data_Dif_2006[i+2,0:3,:,:], axis=0)\n",
    "    \n",
    "    Data_year_spring[i,0:size_2004[2],:] = np.nanmean(Data_Dif_2004[i, 3:6,:,:], axis=0)\n",
    "    Data_year_spring[i,size_2004[2]:size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+1, 3:6,:,:], axis=0)\n",
    "    Data_year_spring[i,size_2004[2]+size_2005[2]:size_2004[2]+size_2005[2]+size_2006[2],:] = np.nanmean(Data_Dif_2006[i+2,3:6,:,:], axis=0)\n",
    "    \n",
    "    Data_year_summer[i,0:size_2004[2],:] = np.nanmean(Data_Dif_2004[i, 6:9,:,:], axis=0)\n",
    "    Data_year_summer[i,size_2004[2]:size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+1, 6:9,:,:], axis=0)\n",
    "    Data_year_summer[i,size_2004[2]+size_2005[2]:size_2004[2]+size_2005[2]+size_2006[2],:] = np.nanmean(Data_Dif_2006[i+2,6:9,:,:], axis=0)\n",
    "    \n",
    "    Data_year_fall[i,0:size_2004[2],:] = np.nanmean(Data_Dif_2004[i, 9:12,:,:], axis=0)\n",
    "    Data_year_fall[i,size_2004[2]:size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+1, 9:12,:,:], axis=0)\n",
    "    Data_year_fall[i,size_2004[2]+size_2005[2]:size_2004[2]+size_2005[2]+size_2006[2],:] = np.nanmean(Data_Dif_2006[i+2,9:12,:,:], axis=0)\n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "output_winter = path + 'Dif_WinterAverage_17years_1BF_15AF_2'\n",
    "np.save(output_winter, Data_year_winter) \n",
    "    \n",
    "output_spring = path + 'Dif_SpringAverage_17years_1BF_15AF_2'\n",
    "np.save(output_spring, Data_year_spring) \n",
    "\n",
    "    \n",
    "output_summer = path + 'Dif_SummerAverage_17years_1BF_15AF_2'\n",
    "np.save(output_summer, Data_year_summer) \n",
    "output_fall = path + 'Dif_FallAverage_17years_1BF_15AF_2'\n",
    "np.save(output_fall, Data_year_fall)\n",
    "import sys\n",
    "sys.modules[__name__].__dict__.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'len_points' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ed3922720e19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0msize_2005\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData_Dif_2005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mData_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_YearAF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mData_year_winter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_YearAF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mData_year_summer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_YearAF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'len_points' is not defined"
     ]
    }
   ],
   "source": [
    "len_YearAF = 17\n",
    "waterYearLen = 19\n",
    "months_total = 228\n",
    "path = '/Users/yunxiazhao/Documents/AAA_burnSnow/data8_10km_monthly/data_100km_3/'\n",
    "\n",
    "Data_Dif_2003 = np.load(path +'Burn_fireYear_2003.npy')\n",
    "Data_Dif_2004 = np.load(path +'Burn_fireYear_2004.npy')\n",
    "Data_Dif_2005 = np.load(path +'Burn_fireYear_2005.npy')\n",
    "size_2003 = np.shape(Data_Dif_2003)\n",
    "size_2004 = np.shape(Data_Dif_2004)\n",
    "size_2005 = np.shape(Data_Dif_2005)\n",
    "\n",
    "Data_year = np.zeros((len_YearAF,len_points,len_var))\n",
    "Data_year_winter = np.zeros((len_YearAF,len_points,len_var))\n",
    "Data_year_summer = np.zeros((len_YearAF,len_points,len_var))\n",
    "Data_year[:]=np.nan\n",
    "Data_year_winter[:]=np.nan\n",
    "Data_year_summer[:]=np.nan\n",
    "for i in range(0, len_YearAF):\n",
    "    Data_year[i,0:size_2003[2],:] = np.nanmean(Data_Dif_2003[i, :,:,:], axis=0)\n",
    "    Data_year[i,size_2003[2]:size_2003[2]+size_2004[2],:] = np.nanmean(Data_Dif_2004[i+1, :,:,:], axis=0)\n",
    "    Data_year[i,size_2003[2]+size_2004[2]:size_2003[2]+size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+2, :,:,:], axis=0)\n",
    "    \n",
    "    \n",
    "    Data_year_winter[i,0:size_2003[2],:] = np.nanmean(Data_Dif_2003[i, 0:6,:,:], axis=0)\n",
    "    Data_year_winter[i,size_2003[2]:size_2003[2]+size_2004[2],:] = np.nanmean(Data_Dif_2004[i+1, 0:6,:,:], axis=0)\n",
    "    Data_year_winter[i,size_2003[2]+size_2004[2]:size_2003[2]+size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+2,0:6,:,:], axis=0)\n",
    "    \n",
    "    Data_year_summer[i,0:size_2003[2],:] = np.nanmean(Data_Dif_2003[i, 6:12,:,:], axis=0)\n",
    "    Data_year_summer[i,size_2003[2]:size_2003[2]+size_2004[2],:] = np.nanmean(Data_Dif_2004[i+1, 6:12,:,:], axis=0)\n",
    "    Data_year_summer[i,size_2003[2]+size_2004[2]:size_2003[2]+size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+2, 6:12,:,:], axis=0)\n",
    "    \n",
    "    \n",
    "output_year = path + 'Burn_YearlyAverage_17years_1BF_15AF'\n",
    "np.save(output_year, Data_year)    \n",
    "    \n",
    "output_winter = path + 'Burn_WinterAverage_17years_1BF_15AF'\n",
    "np.save(output_winter, Data_year_winter) \n",
    "    \n",
    "output_summer = path + 'Burn_SummerAverage_17years_1BF_15AF'\n",
    "np.save(output_summer, Data_year_summer) \n",
    "import sys\n",
    "sys.modules[__name__].__dict__.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_YearAF = 17\n",
    "waterYearLen = 19\n",
    "months_total = 228\n",
    "path = '/Users/yunxiazhao/Documents/AAA_burnSnow/data8_10km_monthly/data_100km_3/'\n",
    "\n",
    "Data_Dif_2003 = np.load(path + 'Unbn_fireYear_2003.npy')\n",
    "Data_Dif_2004 = np.load(path + 'Unbn_fireYear_2004.npy')\n",
    "Data_Dif_2005 = np.load(path + 'Unbn_fireYear_2005.npy')\n",
    "size_2003 = np.shape(Data_Dif_2003)\n",
    "size_2004 = np.shape(Data_Dif_2004)\n",
    "size_2005 = np.shape(Data_Dif_2005)\n",
    "\n",
    "Data_year = np.zeros((len_YearAF,len_points,len_var))\n",
    "Data_year_winter = np.zeros((len_YearAF,len_points,len_var))\n",
    "Data_year_summer = np.zeros((len_YearAF,len_points,len_var))\n",
    "Data_year[:]=np.nan\n",
    "Data_year_winter[:]=np.nan\n",
    "Data_year_summer[:]=np.nan\n",
    "for i in range(0, len_YearAF):\n",
    "    Data_year[i,0:size_2003[2],:] = np.nanmean(Data_Dif_2003[i, :,:,:], axis=0)\n",
    "    Data_year[i,size_2003[2]:size_2003[2]+size_2004[2],:] = np.nanmean(Data_Dif_2004[i+1, :,:,:], axis=0)\n",
    "    Data_year[i,size_2003[2]+size_2004[2]:size_2003[2]+size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+2, :,:,:], axis=0)\n",
    "    \n",
    "    \n",
    "    Data_year_winter[i,0:size_2003[2],:] = np.nanmean(Data_Dif_2003[i, 0:6,:,:], axis=0)\n",
    "    Data_year_winter[i,size_2003[2]:size_2003[2]+size_2004[2],:] = np.nanmean(Data_Dif_2004[i+1, 0:6,:,:], axis=0)\n",
    "    Data_year_winter[i,size_2003[2]+size_2004[2]:size_2003[2]+size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+2,0:6,:,:], axis=0)\n",
    "    \n",
    "    Data_year_summer[i,0:size_2003[2],:] = np.nanmean(Data_Dif_2003[i, 6:12,:,:], axis=0)\n",
    "    Data_year_summer[i,size_2003[2]:size_2003[2]+size_2004[2],:] = np.nanmean(Data_Dif_2004[i+1, 6:12,:,:], axis=0)\n",
    "    Data_year_summer[i,size_2003[2]+size_2004[2]:size_2003[2]+size_2004[2]+size_2005[2],:] = np.nanmean(Data_Dif_2005[i+2, 6:12,:,:], axis=0)\n",
    "    \n",
    "    \n",
    "output_year = path  + 'Unbn_YearlyAverage_17years_1BF_15AF'\n",
    "np.save(output_year, Data_year)    \n",
    "    \n",
    "output_winter = path  + 'Unbn_WinterAverage_17years_1BF_15AF'\n",
    "np.save(output_winter, Data_year_winter) \n",
    "    \n",
    "output_summer = path  + 'Unbn_SummerAverage_17years_1BF_15AF'\n",
    "np.save(output_summer, Data_year_summer) \n",
    "import sys\n",
    "sys.modules[__name__].__dict__.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_YearAF = 17\n",
    "waterYearLen = 19\n",
    "months_total = 228\n",
    "path = '/Users/yunxiazhao/Documents/AAA_burnSnow/data8_10km_monthly/data_100km_3/'\n",
    "\n",
    "Data_Dif_2003 = np.load(path + 'Dif_fireYear_2003.npy')\n",
    "Data_Dif_2004 = np.load(path + 'Dif_fireYear_2004.npy')\n",
    "Data_Dif_2005 = np.load(path + 'Dif_fireYear_2005.npy')\n",
    "size_2003 = np.shape(Data_Dif_2003)\n",
    "size_2004 = np.shape(Data_Dif_2004)\n",
    "size_2005 = np.shape(Data_Dif_2005)\n",
    "\n",
    "Data_year = np.zeros((len_YearAF,len_points*12,len_var))\n",
    "Data_year_winter = np.zeros((len_YearAF,len_points*6,len_var))\n",
    "Data_year_summer = np.zeros((len_YearAF,len_points*6,len_var))\n",
    "Data_year[:]=np.nan\n",
    "Data_year_winter[:]=np.nan\n",
    "Data_year_summer[:]=np.nan\n",
    "for i in range(0, len_YearAF): \n",
    "    a=np.reshape(Data_Dif_2003[i,:,:,:],(-1,len_var))\n",
    "    b=np.reshape(Data_Dif_2004[i+1,:,:,:],(-1,len_var))\n",
    "    c=np.reshape(Data_Dif_2005[i+2,:,:,:],(-1,len_var))\n",
    "\n",
    "    \n",
    "    Data_year[i,:,:] = np.concatenate((a,b,c), axis=0)\n",
    "    a=np.reshape(Data_Dif_2003[i,0:6,:,:],(-1,len_var))\n",
    "    b=np.reshape(Data_Dif_2004[i+1,0:6,:,:],(-1,len_var))\n",
    "    c=np.reshape(Data_Dif_2005[i+2,0:6,:,:],(-1,len_var))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    Data_year_winter[i,:,:] = np.concatenate((a,b,c), axis=0)\n",
    "    a=np.reshape(Data_Dif_2003[i,6:12,:,:],(-1,len_var))\n",
    "    b=np.reshape(Data_Dif_2004[i+1,6:12,:,:],(-1,len_var))\n",
    "    c=np.reshape(Data_Dif_2005[i+2,6:12,:,:],(-1,len_var))\n",
    "    \n",
    "\n",
    "    \n",
    "    Data_year_summer[i,:,:] = np.concatenate((a,b,c), axis=0)\n",
    "                                           \n",
    "    \n",
    "    \n",
    "output_year = path + 'Dif_YearlyAllData_17years_1BF_15AF'\n",
    "np.save(output_year, Data_year)    \n",
    "    \n",
    "output_winter =path + 'Dif_WinterAllData_17years_1BF_15AF'\n",
    "np.save(output_winter, Data_year_winter) \n",
    "    \n",
    "output_summer = path + 'Dif_SummerAllData_17years_1BF_15AF'\n",
    "np.save(output_summer, Data_year_summer) \n",
    "import sys\n",
    "sys.modules[__name__].__dict__.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_YearAF = 17\n",
    "waterYearLen = 19\n",
    "months_total = 228\n",
    "path = '/Users/yunxiazhao/Documents/AAA_burnSnow/data8_10km_monthly/data_100km_3/'\n",
    "\n",
    "Data_Dif_2003 = np.load(path + 'Burn_fireYear_2003.npy')\n",
    "Data_Dif_2004 = np.load(path + 'Burn_fireYear_2004.npy')\n",
    "Data_Dif_2005 = np.load(path + 'Burn_fireYear_2005.npy')\n",
    "size_2003 = np.shape(Data_Dif_2003)\n",
    "size_2004 = np.shape(Data_Dif_2004)\n",
    "size_2005 = np.shape(Data_Dif_2005)\n",
    "\n",
    "Data_year = np.zeros((len_YearAF,len_points*12,len_var))\n",
    "Data_year_winter = np.zeros((len_YearAF,len_points*6,len_var))\n",
    "Data_year_summer = np.zeros((len_YearAF,len_points*6,len_var))\n",
    "Data_year[:]=np.nan\n",
    "Data_year_winter[:]=np.nan\n",
    "Data_year_summer[:]=np.nan\n",
    "for i in range(0, len_YearAF): \n",
    "    a=np.reshape(Data_Dif_2003[i,:,:,:],(-1,len_var))\n",
    "    b=np.reshape(Data_Dif_2004[i+1,:,:,:],(-1,len_var))\n",
    "    c=np.reshape(Data_Dif_2005[i+2,:,:,:],(-1,len_var))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    Data_year[i,:,:] = np.concatenate((a,b,c), axis=0)\n",
    "    a=np.reshape(Data_Dif_2003[i,0:6,:,:],(-1,len_var))\n",
    "    b=np.reshape(Data_Dif_2004[i+1,0:6,:,:],(-1,len_var))\n",
    "    c=np.reshape(Data_Dif_2005[i+2,0:6,:,:],(-1,len_var))\n",
    "\n",
    "    \n",
    "    \n",
    "    Data_year_winter[i,:,:] = np.concatenate((a,b,c), axis=0)\n",
    "    a=np.reshape(Data_Dif_2003[i,6:12,:,:],(-1,len_var))\n",
    "    b=np.reshape(Data_Dif_2004[i+1,6:12,:,:],(-1,len_var))\n",
    "    c=np.reshape(Data_Dif_2005[i+2,6:12,:,:],(-1,len_var))\n",
    "    \n",
    "\n",
    "    \n",
    "    Data_year_summer[i,:,:] = np.concatenate((a,b,c), axis=0)\n",
    "                                           \n",
    "    \n",
    "    \n",
    "output_year = path  + 'Burn_YearlyAllData_17years_1BF_15AF'\n",
    "np.save(output_year, Data_year)    \n",
    "    \n",
    "output_winter = path + 'Burn_WinterAllData_17years_1BF_15AF'\n",
    "np.save(output_winter, Data_year_winter) \n",
    "    \n",
    "output_summer = path  + 'Burn_SummerAllData_17years_1BF_15AF'\n",
    "np.save(output_summer, Data_year_summer) \n",
    "import sys\n",
    "sys.modules[__name__].__dict__.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_YearAF = 17\n",
    "waterYearLen = 19\n",
    "months_total = 228\n",
    "path = '/Users/yunxiazhao/Documents/AAA_burnSnow/data8_10km_monthly/data_100km_3/'\n",
    "\n",
    "Data_Dif_2003 = np.load(path  + 'Unbn_fireYear_2003.npy')\n",
    "Data_Dif_2004 = np.load(path  + 'Unbn_fireYear_2004.npy')\n",
    "Data_Dif_2005 = np.load(path  + 'Unbn_fireYear_2005.npy')\n",
    "size_2003 = np.shape(Data_Dif_2003)\n",
    "size_2004 = np.shape(Data_Dif_2004)\n",
    "size_2005 = np.shape(Data_Dif_2005)\n",
    "\n",
    "Data_year = np.zeros((len_YearAF,len_points*12,len_var))\n",
    "Data_year_winter = np.zeros((len_YearAF,len_points*6,len_var))\n",
    "Data_year_summer = np.zeros((len_YearAF,len_points*6,len_var))\n",
    "Data_year[:]=np.nan\n",
    "Data_year_winter[:]=np.nan\n",
    "Data_year_summer[:]=np.nan\n",
    "for i in range(0, len_YearAF): \n",
    "    a=np.reshape(Data_Dif_2003[i,:,:,:],(-1,len_var))\n",
    "    b=np.reshape(Data_Dif_2004[i+1,:,:,:],(-1,len_var))\n",
    "    c=np.reshape(Data_Dif_2005[i+2,:,:,:],(-1,len_var))\n",
    "    \n",
    " \n",
    "    \n",
    "    Data_year[i,:,:] = np.concatenate((a,b,c), axis=0)\n",
    "    a=np.reshape(Data_Dif_2003[i,0:6,:,:],(-1,len_var))\n",
    "    b=np.reshape(Data_Dif_2004[i+1,0:6,:,:],(-1,len_var))\n",
    "    c=np.reshape(Data_Dif_2005[i+2,0:6,:,:],(-1,len_var))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    Data_year_winter[i,:,:] = np.concatenate((a,b,c), axis=0)\n",
    "    a=np.reshape(Data_Dif_2003[i,6:12,:,:],(-1,len_var))\n",
    "    b=np.reshape(Data_Dif_2004[i+1,6:12,:,:],(-1,len_var))\n",
    "    c=np.reshape(Data_Dif_2005[i+2,6:12,:,:],(-1,len_var))\n",
    "\n",
    "    \n",
    "    \n",
    "    Data_year_summer[i,:,:] = np.concatenate((a,b,c), axis=0)\n",
    "                                           \n",
    "                                           \n",
    "    \n",
    "    \n",
    "output_year = path  + 'Unbn_YearlyAllData_17years_1BF_15AF'\n",
    "np.save(output_year, Data_year)    \n",
    "    \n",
    "output_winter = path + 'Unbn_WinterAllData_17years_1BF_15AF'\n",
    "np.save(output_winter, Data_year_winter) \n",
    "    \n",
    "output_summer = path  + 'Unbn_SummerAllData_17years_1BF_15AF'\n",
    "np.save(output_summer, Data_year_summer) \n",
    "import sys\n",
    "sys.modules[__name__].__dict__.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_YearAF = 17\n",
    "waterYearLen = 19\n",
    "months_total = 228\n",
    "path = '/Users/yunxiazhao/Documents/AAA_burnSnow/data8_10km_monthly/data_100km_3/'\n",
    "\n",
    "def globalTObasin(dataTag):\n",
    "    Data_Burn_2003 = np.load(path + dataTag + '_fireYear_2003.npy')\n",
    "    Data_Burn_2004 = np.load(path + dataTag + '_fireYear_2004.npy')\n",
    "    Data_Burn_2005 = np.load(path + dataTag + '_fireYear_2005.npy')\n",
    "    basin_ID = [3020024310, 4020050210, 4020050220, 1020040190, 4020050290, 4020050470, 7020000010, 6020000010, 3020000010, 1020000010, 8020000010, 4020000010, 5020000010, 2020000010, 9020000010, 7020014250, 6020006540, 3020003790, 8020008900, 4020006940, 5020015660, 2020003440, 7020021430, 3020005240, 1020018110, 8020010700, 4020015090, 5020037270, 2020018240, 7020024600, 3020008670, 1020021940, 8020020760, 4020024190, 2020024230, 7020038340, 3020009320, 1020027430, 8020022890, 4020034510, 5020054880, 2020033490, 1020034170, 8020032840, 2020041390, 7020046750, 7020047840, 6020029280, 8020044560, 2020057170, 7020065090, 2020065840, 2020071190]\n",
    "    data = np.zeros((waterYearLen, 12, 53, len_var))\n",
    "    count_sum = 0\n",
    "    data_all = np.zeros((3, waterYearLen, 12, 53, len_var))\n",
    "    for year in range(0, 3):\n",
    "        if year == 0:\n",
    "            Data_fireYear = Data_Burn_2003\n",
    "        if year == 1:\n",
    "            Data_fireYear = Data_Burn_2004\n",
    "        if year == 2:\n",
    "            Data_fireYear = Data_Burn_2005\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "        for i in range(0, 53):\n",
    "            count = np.count_nonzero(Data_fireYear[:, :, :, 2] == basin_ID[i])\n",
    "            index = np.where(Data_fireYear[:,:,:,2] == basin_ID[i])\n",
    "            index_x = index[0]\n",
    "            index_y = index[1]\n",
    "            index_z = index[2]\n",
    "            rows = int(count / waterYearLen / 12)\n",
    "            item_biomeType = np.zeros((waterYearLen, 12, rows, len_var))\n",
    "            item_biomeType[:]=np.nan\n",
    "\n",
    "            for j in range(0, count):\n",
    "                item_biomeType[index_x[j], index_y[j], j % rows, :] = Data_fireYear[index_x[j], index_y[j], index_z[j], :]\n",
    "            data[:,:,i,:] = np.nanmean(item_biomeType, axis=2)\n",
    "            data_all[year, :, :, i, :] = np.nanmean(item_biomeType, axis=2)\n",
    "    output = path + dataTag  + '_forEachBasin'\n",
    "    np.save(output, data_all)\n",
    "\n",
    "dataTag = 'Burn'\n",
    "globalTObasin(dataTag)\n",
    "\n",
    "dataTag = 'Unbn'\n",
    "globalTObasin(dataTag)\n",
    "\n",
    "dataTag = 'Dif'\n",
    "globalTObasin(dataTag)\n",
    "import sys\n",
    "sys.modules[__name__].__dict__.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_YearAF = 17\n",
    "waterYearLen = 19\n",
    "months_total = 228\n",
    "path = '/Users/yunxiazhao/Documents/AAA_burnSnow/data8_10km_monthly/data_100km_3/'\n",
    "\n",
    "def globalTOcontinent(dataTag):\n",
    "    Data_Burn_2003 = np.load(path + dataTag + '_fireYear_2003.npy')\n",
    "    Data_Burn_2004 = np.load(path + dataTag + '_fireYear_2004.npy')\n",
    "    Data_Burn_2005 = np.load(path + dataTag + '_fireYear_2005.npy')\n",
    "    basin_ID = [3020024310, 4020050210, 4020050220, 1020040190, 4020050290, 4020050470, 7020000010, 6020000010, 3020000010, 1020000010, 8020000010, 4020000010, 5020000010, 2020000010, 9020000010, 7020014250, 6020006540, 3020003790, 8020008900, 4020006940, 5020015660, 2020003440, 7020021430, 3020005240, 1020018110, 8020010700, 4020015090, 5020037270, 2020018240, 7020024600, 3020008670, 1020021940, 8020020760, 4020024190, 2020024230, 7020038340, 3020009320, 1020027430, 8020022890, 4020034510, 5020054880, 2020033490, 1020034170, 8020032840, 2020041390, 7020046750, 7020047840, 6020029280, 8020044560, 2020057170, 7020065090, 2020065840, 2020071190]\n",
    "    continent_ID = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "    count_sum = 0\n",
    "    data_all = np.zeros((3,waterYearLen, 12, 9,  len_var))\n",
    "\n",
    "    for year in range(0, 3):\n",
    "        if year == 0:\n",
    "            Data_fireYear = Data_Burn_2003\n",
    "        if year == 1:\n",
    "            Data_fireYear = Data_Burn_2004\n",
    "        if year == 2:\n",
    "            Data_fireYear = Data_Burn_2005\n",
    " \n",
    "            \n",
    "            \n",
    "        for i in range(0, 9):\n",
    "            basin = Data_fireYear[:, :, :, 2]\n",
    "            count = np.count_nonzero(np.floor(basin/1000000000) == continent_ID[i])\n",
    "            index = np.where(np.floor(basin/1000000000) == continent_ID[i])\n",
    "\n",
    "            index_x = index[0]\n",
    "            index_y = index[1]\n",
    "            index_z = index[2]\n",
    "            rows = int(count / waterYearLen / 12)\n",
    "            item_biomeType = np.zeros((waterYearLen, 12, rows, len_var))\n",
    "            item_biomeType[:] = np.nan\n",
    "            for j in range(0, count):\n",
    "                item_biomeType[index_x[j], index_y[j], j % rows, :] = Data_fireYear[index_x[j], index_y[j], index_z[j], :]\n",
    "            data_all[year, :, :, i, :] = np.nanmean(item_biomeType, axis=2)\n",
    "    output = path + dataTag  + '_forEachContinent'\n",
    "    np.save(output, data_all)\n",
    "\n",
    "dataTag = 'Burn'\n",
    "globalTOcontinent(dataTag)\n",
    "\n",
    "dataTag = 'Unbn'\n",
    "globalTOcontinent(dataTag)\n",
    "\n",
    "dataTag = 'Dif'\n",
    "globalTOcontinent(dataTag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.modules[__name__].__dict__.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
